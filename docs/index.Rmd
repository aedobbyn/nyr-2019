---
title: "This Talk is on Fire"
subtitle: "`Using Twitter and Google to Track Fires in NYC`"
author: "Amanda Dobbyn"
output:
  xaringan::moon_reader:
    css: ["default", "shinobi", "dobbs.css"]
    lib_dir: libs
    includes:
      in_header: header.html
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      navigation:
        scroll: false
---

```{r setup, include=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)
opts_chunk$set(echo = TRUE, eval = TRUE, collapse = TRUE, cache = TRUE)
options(htmltools.dir.version = FALSE)
options(knitr.table.format = "html")
```


class: inverse

## Quick About Me

<br>

.left-column[

**Day job**: Data Scientist at [Earlybird Software](http://www.earlybird.co/), former co-organizer of [R-Ladies Chicago](https://rladieschicago.org/)

**For fun**: ultimate frisbee player
<!-- .pull-left[![](./img/pingpong.jpg)] -->

**GitHub**: [@aedobbyn](https://github.com/aedobbyn)

**Website**: https://dobb.ae

**Twitter**: [@dobbleobble](https://twitter.com/dobbleobble)

]

.right-column[![](./img/fris.jpg)]

---

## This Talk

<br>

- Will use Twitter and Google Maps geocoding APIs to figure out when and where fires happen in NYC

--

<br>
<br>
<br>
<br>
<br>

All code and slides on [GitHub](https://github.com/aedobbyn/nyr-2019).


---

class: blue-light 

<!-- background-image: url("https://static01.nyt.com/images/2018/12/29/nyregion/28xp-explosion-sub-print/28xp-explosion-sub-facebookJumbo.jpg) -->

## Our Plan

Remember the [crazy blue light](https://twitter.com/NYCFireWire/status/1078478369036165121) in NYC from late December?

--

<p align="left" style="padding-right: 20%;">
<img src="./img/blue_light.jpg" height="350px">
</p>

--

`r emo::ji("scream")` `r emo::ji("scream")` `r emo::ji("scream")`


---

## Our Plan

.pull-right[![](./img/nyc_fire.jpg)]

<br>

The Twitter account that let us know that this wasn't in fact aliens is [NYCFireWire](https://twitter.com/NYCFireWire).

<br>

Normally they just tweet out fires and their locations in a more or less predictable pattern:

<br>


--
Before February:

`<borough> ** <some numbers> ** <address> <description of fire>`

After February:

`<borough> *<type of fire>* Box <digits> <address> <description of fire>`

<br>


We can use their tweets to get some info on where and when fires happen in NYC.


???

I'll illustrate a way you might want to use `drake` with something that's close to home for us.

What if we were constructing an analysis of these tweets and wanted to make sure our pipeline worked end-to-end, but didn't want to unnecessarily re-run outdated parts of it unless we needed to?


---

## The Pipeline

1. Pull in tweets, either the first big batch or any new ones that show up

--

2. Extract addresses from the tweets (`r emo::ji("notes")` regex time `r emo::ji("notes")`)

--

3. Send addresses to the Google Maps API to grab their latitudes and longitudes

--

4. Profit

--

<br>

All functions are defined in [`didnt_start_it.R`](https://github.com/aedobbyn/nyc-fires/blob/master/R/didnt_start_it.R), which we'll source in now.

```{r, warning=FALSE, message=FALSE}
source(here::here("R", "didnt_start_it.R")) 
```

--

<br>

**Caveats**

This analysis relies on the [rtweet](https://github.com/mkearney/rtweet) and [ggmap](https://github.com/dkahle/ggmap) packages.

To be able to run it in full you'll need a [Twitter API access token](https://rtweet.info/articles/auth.html) and [Google Maps Geocoding API key](https://developers.google.com/maps/documentation/geocoding/intro#Geocoding).

---

## Grabbing Tweets

**Pull in tweets, either the first big batch or any new ones that show up**

- This way we can run the same function to look for more tweets at any time, if they exist



---

## Grabbing a Seed Batch of Tweets

```{r}
get_seed_tweets <- function(user = firewire_handle,
                            n_tweets = 50,
                            max_id = NULL, # Max ID of the tweet
                            input_path = NULL, # Read from a file or grab from Twitter?
                            output_path = NULL,
                            write_out = FALSE,
                            verbose = TRUE) {
  if (!is.null(input_path) && file_exists(input_path)) {
    if (verbose) message("Reading in tweets from CSV.")
    out <-
      read_csv(input_path,
        col_types =
          list(
            text = col_character(),
            user_id = col_character(),
            status_id = col_character(),
            created_at = col_datetime(format = ""),
            screen_name = col_character()
          )
      )
  } else {
    out <-
      get_timeline(user = user, n = n_tweets, max_id = max_id) %>%
      mutate(
        user_id = as.character(user_id),
        status_id = as.character(status_id),
        created_at = # UTC by default
        lubridate::as_datetime(created_at, tz = "America/New_York")
      ) %>%
      select(text, user_id, status_id, created_at, screen_name) %>%
      arrange(desc(created_at))
  }

  if (!is.null(output_path) && write_out == TRUE) {
    write_csv(out, output_path)
  }

  out
}
```


```{r}
# Check if there are new tweets at an account
there_are_new_tweets <- function(tbl,
                                 user = firewire_handle,
                                 verbose = TRUE) {
  latest_dt <-
    tbl %>%
    arrange(desc(created_at)) %>%
    slice(1) %>%
    pull(created_at)

  if (verbose) message("Searching for new tweets.")

  new <- get_seed_tweets(user = user, n_tweets = 1)

  if (max(new$created_at) <= latest_dt) {
    if (verbose) message("No new tweets to pull.")
    FALSE
  } else {
    TRUE
  }
}
```


```{r}
# Given a tbl of tweets, reup if there_are_new_tweets()
get_more_tweets <- function(tbl,
                            user = firewire_handle,
                            n_tweets = 20,
                            verbose = TRUE) {
  if (!there_are_new_tweets(tbl = tbl, user = user)) {
    return(NULL)
  }

  new <- get_seed_tweets(user = user, n_tweets = n_tweets)

  out <-
    new %>%
    filter(created_at > max(tbl$created_at))

  if (verbose) message(glue("{nrow(out)} new tweet(s) pulled."))

  out
}
```



---

## Grabbing Tweets

[`get_tweets`](https://github.com/aedobbyn/nyc-fires/blob/master/R/didnt_start_it.R)

```{r}
get_tweets <- function(tbl = NULL,
                       user = firewire_handle,
                       max_id = NULL,
                       n_tweets_seed = 10,
                       n_tweets_reup = 5,
                       input_path = NULL,
                       output_path = NULL,
                       write_out = TRUE,
                       verbose = TRUE) {
  if (is.null(tbl) || is.na(tbl)) {
    out <- get_seed_tweets(
      user = user,
      n_tweets = n_tweets_seed,
      input_path = input_path,
      output_path = output_path,
      write_out = FALSE,
      max_id = max_id
    )
  } else {
    new <-
      get_more_tweets(tbl, user = user, n_tweets = n_tweets_reup, verbose = verbose)

    out <-
      tbl %>%
      bind_rows(new) %>%
      arrange(desc(created_at))
  }

  # Always write to file
  if (!is.null(output_path) && write_out == TRUE) {
    write_csv(out, output_path)
  }

  out
}
```




---

## Grabbing Tweets

[`get_tweets`](https://github.com/aedobbyn/nyc-fires/blob/master/R/didnt_start_it.R)

--

*Main idea*: 

* **Builds up a file** of the most recent set of tweets from a given account

--

*Details*:
- If neither file nor `tbl` is supplied as arguments, grabs an initial *seed* batch of tweets
- If either is supplied, checks for new tweets and grabs them if any
- Spits out the latest to the same file

```{r, include=FALSE}
get_seed_tweets

get_more_tweets

get_tweets
```

<br>

```{r}
get_tweets(n_tweets_seed = 3)
```

???

- `get_seed_tweets` grabs a batch of tweets *or* reads in seed tweets from a file if the file exists
- `get_more_tweets` checks if there are new tweets and, if so, pulls in the right number of them
- `get_tweets` runs `get_seed_tweets` if given a null `tbl` argument, otherwise runs `get_more_tweets`


---

## Grabbing Seed Tweets

A closer look at just the text of the tweets:

```{r}
get_tweets(n_tweets_seed = 5) %>% 
  select(text) %>% 
  kable()
```


---

## Reupping Tweets

To show how `get_tweets` can start with a `tbl` of tweets and look for new ones,

we'll grab 10 `seed_tweets` that are all **older** than an old tweet ID.

--

<br>

```{r}
old_tweet_id <- "1084948074588487680" # From Jan 14

seed_tweets <- 
  get_tweets(
    n_tweets_seed = 10,
    max_id = old_tweet_id
  )

nrow(seed_tweets)
```

---

## Reupping Tweets

Using `seed_tweets` as an input to the same `get_tweets` function,

we check for new tweets, and, if there are any, pull them in.

--

```{r}
full_tweets <- 
  get_tweets(seed_tweets, 
             n_tweets_reup = 5)
```

--

<br>

```{r}
nrow(seed_tweets)
nrow(full_tweets)
```


---

## Getting Addresses

With `pull_addresses` we parse the text of the tweet to pull out borough and street and string them together into an address.

```{r}
pull_addresses <- function(tbl) {
  tbl %>%
    mutate(
      text = str_replace_all(text, "&amp;", "&"),
      borough = str_extract(text, "^[^\\s]*\\s") %>%
        str_remove("\\s"),
      street =
        case_when(
          str_detect(text, "Box") ~ pull_box_address(text),
          TRUE ~ pull_non_box_address(text)
        )
    ) %>%
    rowwise() %>%
    mutate(
      borough =
        case_when(
          str_detect(borough, borough_reg) ~ borough %>% clean_borough(),
          TRUE ~ NA_character_
        ),
      address =
        glue::glue("{street}, {borough}", .na = "") %>%
          str_remove("[, ]?") %>%
          str_trim()
    ) %>%
    mutate(
      address = na_if(address, "")
    ) %>%
    select(borough, street, address, text, created_at)
}
```


---

## Getting Addresses

```{r}
get_tweets(max_id = old_tweet_id) %>% 
  pull_addresses() %>%  #<<
  select(text, street, borough, address) %>% 
  kable() 
```

---

## Getting Lat and Long

Last step of the main pipeline! 

--

**Reverse geocoding** = getting latitude and longitude from an address.

The [`ggmap`](https://www.rdocumentation.org/packages/ggmap/versions/2.6.1/topics/geocode) package exposes this feature of the [Google Maps](https://cloud.google.com/maps-platform/) API.

<br>

The `ggmap::geocode` accepts a string and returns a dataframe of `lon` and `lat`.

```{r}
(sherlock <- ggmap::geocode("221B Baker Street, London", messaging = FALSE))
```

---

Where's Sherlock?

```{r}
get_map("london", zoom = 13) %>% 
  ggmap() +
  geom_point(data = sherlock, aes(x = lon, y = lat), color = "blue", size = 15)
```

---

![](https://media.giphy.com/media/EVjAANNjkMBKE/giphy.gif)

---

So we can put that together into a function that works on a tibble.


```{r}
get_lat_long <- function(tbl) {
  tbl %>%
    mutate(
      address =
        case_when(
          is.na(address) ~ "", # Gives an NA in lat and long response df
          TRUE ~ address
        ),
      l_l = address %>%
        geocode() %>%
        list()
    ) %>%
    unnest() %>%
    select(address, lat, lon, created_at, text) %>%
    rename(long = lon)
}
```


---

## Downstream Analysis

Later in the pipeline we'll:

`count_fires`, summing up the total number of fires per `lat`-`long` combo

<br>

```{r}
count_fires <- function(tbl) {
  tbl %>%
    drop_na() %>%
    count(lat, long)
}
```

<br>

and plot them on a map (thanks again, `ggmap`)

---

## Counting Up

```{r}
fire_sums %>% 
  arrange(desc(n)) %>% 
  slice(1:10)
```


---

## Mapping

```{r}
get_map("new york city") %>% 
  ggmap()
```


---

```{r}
plot_fire_sums <- function(tbl, city = nyc_map,
                           output_path = 
                             here("plots", "fire_sums_plot.png"),
                           ...) {
  tbl <-
    tbl %>%
    drop_na(lat, long)

  fire_layer <-
    geom_point(
      data = tbl, aes(long, lat, size = n),
      color = "red", alpha = 0.5
    )

  plt <- ggmap(nyc_map) +
    fire_layer +
    ggtitle("Fires were Started") +
    labs(x = "Longitude", y = "Latitude",
         size = "Number of Fires") +
    theme_light()

  if (!is.null(output_path)) {
    ggsave(output_path,
      device = "png"
    )
  } else {
    plt
  }
}
```


---

```{r, echo=FALSE, message=FALSE}
fire_sums <-
  read_csv(here("data", "derived", "fire_sums.csv"))
```


Using 3000 tweets:

```{r, message=FALSE, warning=FALSE}
plot_fire_sums(fire_sums, output_path = NULL)
```


<!-- <p> -->
<!-- <img src="./img/fire_sums_plot.png"> -->
<!-- </p> -->
 

---

## How would this look in a `drake` plan?


```{r}
plan <-
  drake_plan(
    seed_fires = get_tweets(), 
    fires = target(
      command = get_tweets(tbl = seed_fires),
        # Always look for new tweets
      trigger = trigger(condition = TRUE) 
    ),
      # Extract addresses from tweets
    addresses = pull_addresses(fires), 
      # Send to Google for lat-longs
    lat_long = get_lat_long(addresses), 
      # Sum up n fires per lat-long combo
    fire_sums = count_fires(lat_long), 

    time_graph = graph_fire_times(lat_long),
    plot = plot_fire_sums(fire_sums)
  )
```

---

## Questions?

```{r}
devtools::session_info()
```


---

class: inverse

<br>

## Thanks!


## `r emo::ji("fire")`

